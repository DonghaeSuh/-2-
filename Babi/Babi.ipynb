{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaad5717-a36c-40c5-b902-b3de847e7d5b",
   "metadata": {},
   "source": [
    "Babi 데이터셋 전처리를 위해 필요한 도구들을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a144abf0-24c2-4f25-8701-ca4bae5271bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import tarfile\n",
    "from nltk import FreqDist\n",
    "from functools import reduce\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a4fe5-50b8-4b9f-89bc-29972e68d866",
   "metadata": {},
   "source": [
    "케라스의 get_file을 통해 데이터셋을 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6329e42d-0bd8-48f1-8aff-6efdcf3ccac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                'babi_tasks_1-20_v1-2.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ffdd3-aa77-4be7-9b95-26f529a3368b",
   "metadata": {},
   "source": [
    "압축을 풀고 훈련 데이터와 테스트 데이터를 각각 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd95b15-bb51-4e16-81da-32940fa3bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(path) as tar:\n",
    " tar.extractall()\n",
    " tar.close()\n",
    "\n",
    "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a8807-9556-41a2-af04-006d86f84027",
   "metadata": {},
   "source": [
    "훈련 데이터로부터 상위 20개의 라인(line)만 읽고 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6f931a9-59fa-4cf0-bf0d-f3bade7797fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.BufferedReader'>\n",
      "1 Mary moved to the bathroom.\n",
      "2 John went to the hallway.\n",
      "3 Where is Mary? \tbathroom\t1\n",
      "4 Daniel went back to the hallway.\n",
      "5 Sandra moved to the garden.\n",
      "6 Where is Daniel? \thallway\t4\n",
      "7 John moved to the office.\n",
      "8 Sandra journeyed to the bathroom.\n",
      "9 Where is Daniel? \thallway\t4\n",
      "10 Mary moved to the hallway.\n",
      "11 Daniel travelled to the office.\n",
      "12 Where is Daniel? \toffice\t11\n",
      "13 John went back to the garden.\n",
      "14 John moved to the bedroom.\n",
      "15 Where is Sandra? \tbathroom\t8\n",
      "1 Sandra travelled to the office.\n",
      "2 Sandra went to the bathroom.\n",
      "3 Where is Sandra? \tbathroom\t2\n",
      "4 Mary went to the bedroom.\n",
      "5 Daniel moved to the hallway.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "lines = open(TRAIN_FILE , \"rb\")\n",
    "for line in lines:\n",
    "    line = line.decode(\"utf-8\").strip()\n",
    "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
    "    i = i + 1\n",
    "    print(line)\n",
    "    if i == 20:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a6fd9-2764-448c-a4a8-af7555f034b1",
   "metadata": {},
   "source": [
    "숫자 1부터 15까지 한 개의 스토리입니다. 그 중간 중간에 질문이 나오고 있습니다. 3번, 6번, 9번, 12번, 15번 라인이 각 스토리 중간에 이어지는 질문에 해당되지요. 그리고 그 각각의 질문 옆에는 질문에 해당되는 정답이 적혀져있고, 그 정답 옆에 나오는 번호는 해당 정답이 몇 번 번호의 라인에 있었는지를 알려줍니다.\n",
    "\n",
    "그리고 숫자 1이 다시 나오면 이제부터는 다시 별개의 스토리가 시작됨을 의미합니다. 이렇게 복잡한 형태의 텍스트를 기계에게 바로 학습시키는 것은 조금 까다롭습니다. 그렇기 때문에 전처리를 거쳐서 스토리, 질문, 답변을 전부 별도로 저장해두겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b36ae5-d55a-4464-9d74-fb95862f603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dir):\n",
    "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
    "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
    "    lines = open(dir, \"rb\")\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.decode(\"utf-8\") # b' 제거\n",
    "        line = line.strip() # '\\n' 제거\n",
    "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
    "        # 여기까지는 모든 줄에 적용되는 전처리\n",
    "\n",
    "        if int(idx) == 1:\n",
    "            story_temp = []\n",
    "\n",
    "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
    "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
    "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
    "            questions.append(question)\n",
    "            answers.append(answer)\n",
    "\n",
    "        else: # 현재 읽는 줄이 스토리인 경우\n",
    "            story_temp.append(text) # 임시 저장\n",
    "\n",
    "    lines.close()\n",
    "    return stories, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a7546d-6f30-4faf-a7e2-ba239159a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_FILE)\n",
    "test_data = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf82d50f-0ff0-4ea9-8bd9-b92404c61a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "495ba699-ea29-4068-96a6-189ed61fb034",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
    "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55cc13cd-bea6-4f30-92bb-a1fccddedd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 스토리의 개수 : 10000\n",
      "훈련용 질문의 개수 : 10000\n",
      "훈련용 답변의 개수 : 10000\n",
      "테스트용 스토리의 개수 : 1000\n",
      "테스트용 질문의 개수 : 1000\n",
      "테스트용 답변의 개수 : 1000\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 스토리의 개수 :', len(train_stories))\n",
    "print('훈련용 질문의 개수 :',len(train_questions))\n",
    "print('훈련용 답변의 개수 :',len(train_answers))\n",
    "print('테스트용 스토리의 개수 :',len(test_stories))\n",
    "print('테스트용 질문의 개수 :',len(test_questions))\n",
    "print('테스트용 답변의 개수 :',len(test_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa77935-8501-4383-b509-91f79d84bb6f",
   "metadata": {},
   "source": [
    "임의로 3,576번째 스토리를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a15be72c-d939-4899-a0e0-eb924d8088ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John went back to the garden.',\n",
       " 'Mary went to the kitchen.',\n",
       " 'Sandra went back to the bedroom.',\n",
       " 'John travelled to the bedroom.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stories[3576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a36370c1-48cb-489a-80ac-061d0055cc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where is John? '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[3576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f687d094-3dec-46f3-a3b3-49322500bb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bedroom'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[3576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdf004-7b3d-4621-80d2-ca3fb11e7734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db42c1fe-0d6b-4c57-abbb-07d642dcf72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return [ x.strip() for x in re.split('(\\W+)', sent) if x and x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a65ff1b1-e620-4a50-bdcc-1d833def6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    counter = FreqDist()\n",
    "\n",
    "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    # 각 샘플의 길이를 저장하는 리스트\n",
    "    story_len = []\n",
    "    question_len = []\n",
    "\n",
    "    for stories, questions, answers in [train_data, test_data]:\n",
    "        for story in stories:\n",
    "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
    "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
    "            for word in stories: # 단어 집합에 단어 추가\n",
    "                counter[word] += 1\n",
    "        for question in questions:\n",
    "            question = tokenize(question)\n",
    "            question_len.append(len(question))\n",
    "            for word in question:\n",
    "                counter[word] += 1\n",
    "        for answer in answers:\n",
    "            answer = tokenize(answer)\n",
    "            for word in answer:\n",
    "                counter[word] += 1\n",
    "\n",
    "    # 단어 집합 생성\n",
    "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
    "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
    "\n",
    "    # 가장 긴 샘플의 길이\n",
    "    story_max_len = np.max(story_len)\n",
    "    question_max_len = np.max(question_len)\n",
    "\n",
    "    return word2idx, idx2word, story_max_len, question_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4829622e-3b50-4e72-9cfc-11da4d8bd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "792afa68-3da5-445a-99c4-577fb114a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bbf2901-0b63-453f-97ba-36bb42368620",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f56339d-c17e-48ac-b503-5012d39bc139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스토리의 최대 길이 : 68\n",
      "질문의 최대 길이 : 4\n"
     ]
    }
   ],
   "source": [
    "print('스토리의 최대 길이 :',story_max_len)\n",
    "print('질문의 최대 길이 :',question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bfd2182-fda1-48a4-a323-9f427bbf5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
    "    Xs, Xq, Y = [], [], []\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "\n",
    "    stories, questions, answers = data\n",
    "    for story, question, answer in zip(stories, questions, answers):\n",
    "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
    "        xq = [word2idx[w] for w in tokenize(question)]\n",
    "        Xs.append(xs)\n",
    "        Xq.append(xq)\n",
    "        Y.append(word2idx[answer])\n",
    "\n",
    "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
    "        # 정답은 원-핫 인코딩\n",
    "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
    "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
    "           to_categorical(Y, num_classes=len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcd1f314-2d2b-4b95-a401-aca10bef4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
    "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4940adf-8e14-417e-ae96-d42ce6f03428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87145508-9cc1-4fb5-8fd8-d4a423dd3faf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 메모리 네트워크로 QA 태스크 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c644e6bd-f9bf-4204-80a2-b0a44e832281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b41d247-b1a5-4c5c-b58f-62385dda37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 횟수\n",
    "train_epochs = 120\n",
    "# 배치 크기\n",
    "batch_size = 32\n",
    "# 임베딩 크기\n",
    "embed_size = 50\n",
    "# LSTM의 크기\n",
    "lstm_size = 64\n",
    "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
    "dropout_rate = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d96b6c-012b-4a5a-86f1-3a9337509875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stories : KerasTensor(type_spec=TensorSpec(shape=(None, 68), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Question: KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n"
     ]
    }
   ],
   "source": [
    "# 플레이스 홀더. 입력을 담는 변수\n",
    "input_sequence = Input((story_max_len,))\n",
    "question = Input((question_max_len,))\n",
    "\n",
    "print('Stories :', input_sequence)\n",
    "print('Question:', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94960d90-5aeb-4e60-b61b-02b49467fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding C\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size))\n",
    "input_encoder_m.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, embedding_dim) \n",
    "#       샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
    "\n",
    "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding A\n",
    "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=question_max_len))\n",
    "input_encoder_c.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, story_max_len, question_max_len) \n",
    "#       샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04a8c8a-5706-43a5-bd3c-ee21f9701273",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12708/3141607522.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 질문을 위한 임베딩. 그림에서의 Embedding B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mquestion_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m question_encoder.add(Embedding(input_dim=vocab_size,\n\u001b[0;32m      4\u001b[0m                                \u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m ))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embed_size,\n",
    "                               input_length=question_max_len))\n",
    "question_encoder.add(Dropout(dropout_rate))\n",
    "# 결과 : (samples, question_max_len, embedding_dim) \n",
    "#       샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "499ce8d3-f166-4940-a0f0-e9b8fe577bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input encoded m KerasTensor(type_spec=TensorSpec(shape=(None, 68, 50), dtype=tf.float32, name=None), name='sequential/dropout/Identity:0', description=\"created by layer 'sequential'\")\n",
      "Input encoded c KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='sequential_1/dropout_1/Identity:0', description=\"created by layer 'sequential_1'\")\n",
      "Question encoded KerasTensor(type_spec=TensorSpec(shape=(None, 4, 50), dtype=tf.float32, name=None), name='sequential_2/dropout_2/Identity:0', description=\"created by layer 'sequential_2'\")\n"
     ]
    }
   ],
   "source": [
    "# 실질적인 임베딩 과정\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "print('Input encoded m', input_encoded_m)\n",
    "print('Input encoded c', input_encoded_c)\n",
    "print('Question encoded', question_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed00f78c-3d9a-4c81-9328-7645e2fc5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match shape KerasTensor(type_spec=TensorSpec(shape=(None, 68, 4), dtype=tf.float32, name=None), name='activation/Softmax:0', description=\"created by layer 'activation'\")\n",
      "Response shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 68), dtype=tf.float32, name=None), name='permute/transpose:0', description=\"created by layer 'permute'\")\n",
      "Answer shape KerasTensor(type_spec=TensorSpec(shape=(None, 4, 118), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
     ]
    }
   ],
   "source": [
    "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
    "# 유사도는 내적을 사용한다.\n",
    "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
    "match = Activation('softmax')(match)\n",
    "print('Match shape', match)\n",
    "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n",
    "\n",
    "response = add([match, input_encoded_c])  \n",
    "# (samples, story_max_len, question_max_len)\n",
    "response = Permute((2, 1))(response) \n",
    "# (samples, question_max_len, story_max_len)\n",
    "print('Response shape', response)\n",
    "\n",
    "# 질문 벡터와 답변 벡터를 연결\n",
    "answer = concatenate([response, question_encoded])\n",
    "print('Answer shape', answer)\n",
    "\n",
    "answer = LSTM(lstm_size)(answer)\n",
    "answer = Dropout(dropout_rate)(answer)\n",
    "answer = Dense(vocab_size)(answer)\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ecd5323-8307-4f40-b37f-07bb42fcdaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 68)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 50)     1100        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 4, 50)        1100        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 68, 4)        0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 68, 4)        0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 4)      88          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 68, 4)        0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 4, 68)        0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 118)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           46848       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 22)           1430        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 22)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50,566\n",
      "Trainable params: 50,566\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/120\n",
      "313/313 [==============================] - 5s 8ms/step - loss: 1.8778 - acc: 0.1801 - val_loss: 1.7721 - val_acc: 0.2260\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.6886 - acc: 0.2726 - val_loss: 1.6293 - val_acc: 0.2900\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.5846 - acc: 0.3532 - val_loss: 1.4852 - val_acc: 0.4120\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.4895 - acc: 0.4222 - val_loss: 1.4298 - val_acc: 0.4530\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.4245 - acc: 0.4550 - val_loss: 1.3695 - val_acc: 0.4710\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3773 - acc: 0.4631 - val_loss: 1.3471 - val_acc: 0.4800\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.3569 - acc: 0.4710 - val_loss: 1.3722 - val_acc: 0.4580\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3460 - acc: 0.4767 - val_loss: 1.2907 - val_acc: 0.5090\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3030 - acc: 0.4890 - val_loss: 1.2583 - val_acc: 0.5130\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2618 - acc: 0.5054 - val_loss: 1.2075 - val_acc: 0.5310\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2333 - acc: 0.5088 - val_loss: 1.2090 - val_acc: 0.5250\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2183 - acc: 0.5147 - val_loss: 1.2120 - val_acc: 0.5060\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2092 - acc: 0.5132 - val_loss: 1.1822 - val_acc: 0.5160\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1841 - acc: 0.5238 - val_loss: 1.1695 - val_acc: 0.5150\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1702 - acc: 0.5236 - val_loss: 1.1616 - val_acc: 0.5250\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1629 - acc: 0.5236 - val_loss: 1.1432 - val_acc: 0.5230\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1642 - acc: 0.5187 - val_loss: 1.1877 - val_acc: 0.5020\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1532 - acc: 0.5208 - val_loss: 1.1477 - val_acc: 0.5220\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1411 - acc: 0.5249 - val_loss: 1.1587 - val_acc: 0.5190\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1332 - acc: 0.5354 - val_loss: 1.1487 - val_acc: 0.5260\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1224 - acc: 0.5263 - val_loss: 1.1516 - val_acc: 0.5170\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1171 - acc: 0.5332 - val_loss: 1.1551 - val_acc: 0.5170\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.1100 - acc: 0.5381 - val_loss: 1.1476 - val_acc: 0.5150\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1018 - acc: 0.5339 - val_loss: 1.1598 - val_acc: 0.5280\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0992 - acc: 0.5400 - val_loss: 1.1399 - val_acc: 0.5310\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0866 - acc: 0.5420 - val_loss: 1.1368 - val_acc: 0.5220\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0754 - acc: 0.5507 - val_loss: 1.1394 - val_acc: 0.5160\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0675 - acc: 0.5539 - val_loss: 1.1518 - val_acc: 0.5320\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.0465 - acc: 0.5704 - val_loss: 1.1205 - val_acc: 0.5470\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.9878 - acc: 0.6015 - val_loss: 0.9957 - val_acc: 0.5990\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.8159 - acc: 0.6936 - val_loss: 0.7668 - val_acc: 0.7160\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6806 - acc: 0.7511 - val_loss: 0.7210 - val_acc: 0.7410\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6161 - acc: 0.7716 - val_loss: 0.6582 - val_acc: 0.7440\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5892 - acc: 0.7775 - val_loss: 0.6175 - val_acc: 0.7650\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5359 - acc: 0.7898 - val_loss: 0.5747 - val_acc: 0.7580\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4852 - acc: 0.8103 - val_loss: 0.5253 - val_acc: 0.7940\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4355 - acc: 0.8296 - val_loss: 0.4695 - val_acc: 0.8190\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4020 - acc: 0.8475 - val_loss: 0.4144 - val_acc: 0.8420\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3701 - acc: 0.8567 - val_loss: 0.4078 - val_acc: 0.8450\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3485 - acc: 0.8680 - val_loss: 0.3798 - val_acc: 0.8610\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3326 - acc: 0.8784 - val_loss: 0.3791 - val_acc: 0.8650\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3167 - acc: 0.8824 - val_loss: 0.3654 - val_acc: 0.8610\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3006 - acc: 0.8864 - val_loss: 0.3524 - val_acc: 0.8760\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2926 - acc: 0.8900 - val_loss: 0.3514 - val_acc: 0.8700\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2784 - acc: 0.8969 - val_loss: 0.3503 - val_acc: 0.8650\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2592 - acc: 0.9026 - val_loss: 0.3306 - val_acc: 0.8790\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2506 - acc: 0.9074 - val_loss: 0.3240 - val_acc: 0.8720\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2330 - acc: 0.9120 - val_loss: 0.3187 - val_acc: 0.8900\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2245 - acc: 0.9187 - val_loss: 0.2578 - val_acc: 0.9080\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2076 - acc: 0.9229 - val_loss: 0.2786 - val_acc: 0.8950\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1838 - acc: 0.9362 - val_loss: 0.2249 - val_acc: 0.9190\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1764 - acc: 0.9379 - val_loss: 0.2281 - val_acc: 0.9170\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1596 - acc: 0.9455 - val_loss: 0.1974 - val_acc: 0.9290\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1431 - acc: 0.9490 - val_loss: 0.1743 - val_acc: 0.9420\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1418 - acc: 0.9520 - val_loss: 0.1668 - val_acc: 0.9500\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1296 - acc: 0.9550 - val_loss: 0.1576 - val_acc: 0.9450\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1225 - acc: 0.9594 - val_loss: 0.1923 - val_acc: 0.9400\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.1119 - acc: 0.9597 - val_loss: 0.1492 - val_acc: 0.9500\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0996 - acc: 0.9652 - val_loss: 0.1581 - val_acc: 0.9400\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1024 - acc: 0.9656 - val_loss: 0.1326 - val_acc: 0.9590\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0947 - acc: 0.9692 - val_loss: 0.1459 - val_acc: 0.9530\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0924 - acc: 0.9686 - val_loss: 0.1507 - val_acc: 0.9540\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0840 - acc: 0.9726 - val_loss: 0.1401 - val_acc: 0.9600\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0836 - acc: 0.9710 - val_loss: 0.1476 - val_acc: 0.9490\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0826 - acc: 0.9732 - val_loss: 0.1856 - val_acc: 0.9400\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0750 - acc: 0.9756 - val_loss: 0.1330 - val_acc: 0.9550\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0767 - acc: 0.9740 - val_loss: 0.1178 - val_acc: 0.9610\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0723 - acc: 0.9753 - val_loss: 0.1357 - val_acc: 0.9540\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0728 - acc: 0.9775 - val_loss: 0.1516 - val_acc: 0.9580\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0698 - acc: 0.9771 - val_loss: 0.1293 - val_acc: 0.9640\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0632 - acc: 0.9783 - val_loss: 0.1291 - val_acc: 0.9590\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0620 - acc: 0.9797 - val_loss: 0.1413 - val_acc: 0.9600\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0601 - acc: 0.9800 - val_loss: 0.1314 - val_acc: 0.9620\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0574 - acc: 0.9813 - val_loss: 0.1379 - val_acc: 0.9580\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0600 - acc: 0.9804 - val_loss: 0.1349 - val_acc: 0.9550\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0582 - acc: 0.9820 - val_loss: 0.1283 - val_acc: 0.9590\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0614 - acc: 0.9817 - val_loss: 0.1315 - val_acc: 0.9620\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0553 - acc: 0.9819 - val_loss: 0.1467 - val_acc: 0.9580\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0496 - acc: 0.9850 - val_loss: 0.1292 - val_acc: 0.9670\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0539 - acc: 0.9826 - val_loss: 0.1345 - val_acc: 0.9590\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0439 - acc: 0.9862 - val_loss: 0.1713 - val_acc: 0.9590\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0446 - acc: 0.9860 - val_loss: 0.1410 - val_acc: 0.9640\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0486 - acc: 0.9847 - val_loss: 0.1516 - val_acc: 0.9580\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0482 - acc: 0.9852 - val_loss: 0.1369 - val_acc: 0.9600\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0419 - acc: 0.9859 - val_loss: 0.1378 - val_acc: 0.9680\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0441 - acc: 0.9861 - val_loss: 0.1410 - val_acc: 0.9650\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0462 - acc: 0.9866 - val_loss: 0.1540 - val_acc: 0.9630\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0466 - acc: 0.9857 - val_loss: 0.1421 - val_acc: 0.9640\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0442 - acc: 0.9872 - val_loss: 0.1181 - val_acc: 0.9690\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0411 - acc: 0.9876 - val_loss: 0.1294 - val_acc: 0.9710\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0392 - acc: 0.9871 - val_loss: 0.1353 - val_acc: 0.9640\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0411 - acc: 0.9882 - val_loss: 0.1391 - val_acc: 0.9630\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0390 - acc: 0.9885 - val_loss: 0.1354 - val_acc: 0.9580\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0437 - acc: 0.9877 - val_loss: 0.1284 - val_acc: 0.9650\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0330 - acc: 0.9901 - val_loss: 0.1230 - val_acc: 0.9680\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0370 - acc: 0.9887 - val_loss: 0.1171 - val_acc: 0.9730\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0326 - acc: 0.9908 - val_loss: 0.1609 - val_acc: 0.9610\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0334 - acc: 0.9895 - val_loss: 0.1142 - val_acc: 0.9690\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0324 - acc: 0.9917 - val_loss: 0.1333 - val_acc: 0.9690\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0337 - acc: 0.9895 - val_loss: 0.1737 - val_acc: 0.9560\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0288 - acc: 0.9917 - val_loss: 0.1611 - val_acc: 0.9640\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0380 - acc: 0.9899 - val_loss: 0.1367 - val_acc: 0.9650\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0344 - acc: 0.9899 - val_loss: 0.1233 - val_acc: 0.9660\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0337 - acc: 0.9910 - val_loss: 0.1223 - val_acc: 0.9720\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0336 - acc: 0.9909 - val_loss: 0.1288 - val_acc: 0.9680\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0303 - acc: 0.9916 - val_loss: 0.1190 - val_acc: 0.9720\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.1338 - val_acc: 0.9700\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0290 - acc: 0.9924 - val_loss: 0.1203 - val_acc: 0.9700\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0264 - acc: 0.9920 - val_loss: 0.1368 - val_acc: 0.9680\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0315 - acc: 0.9920 - val_loss: 0.1284 - val_acc: 0.9700\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0313 - acc: 0.9914 - val_loss: 0.1267 - val_acc: 0.9720\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0272 - acc: 0.9931 - val_loss: 0.1472 - val_acc: 0.9660\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0236 - acc: 0.9921 - val_loss: 0.1340 - val_acc: 0.9650\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0276 - acc: 0.9917 - val_loss: 0.1475 - val_acc: 0.9710\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0274 - acc: 0.9930 - val_loss: 0.1333 - val_acc: 0.9690\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0253 - acc: 0.9932 - val_loss: 0.1329 - val_acc: 0.9660\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0277 - acc: 0.9928 - val_loss: 0.1208 - val_acc: 0.9680\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0295 - acc: 0.9916 - val_loss: 0.1544 - val_acc: 0.9640\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0280 - acc: 0.9924 - val_loss: 0.1452 - val_acc: 0.9650\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0269 - acc: 0.9926 - val_loss: 0.1273 - val_acc: 0.9670\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit([Xstrain, Xqtrain],\n",
    "         Ytrain, batch_size, train_epochs,\n",
    "         validation_data=([Xstest, Xqtest], Ytest))\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "599daee0-bb65-486a-bced-7cddcc70bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1273 - acc: 0.9670\n",
      "\n",
      " 테스트 정확도: 0.9670\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86a96d49-d6de-463f-bb6e-6096c5f5f7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ytest = np.argmax(Ytest, axis=1)\n",
    "\n",
    "Ytest_ = model.predict([Xstest, Xqtest])\n",
    "ytest_ = np.argmax(Ytest_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e6a82-fbf7-43b7-8b26-c7be7f9a6ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
